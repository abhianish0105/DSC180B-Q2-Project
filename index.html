<!DOCTYPE html>
<html lang="en">
  
  <head>
  <meta charset="UTF-8">
  <title>Analyzing Gun Control Sentiments On Twitter | project-presentation</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#157878">
  <link rel="stylesheet" href="./css/normalize.css">
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="./css/cayman.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <script> 
    $(function(){$("#includedContent").load("lda_cgs_vs_gensim.html");});
  </script>
</head>

  <body>
    <header class="page-header" role="banner">
      <h1 class="project-name">Analyzing Gun Control Sentiments On Twitter</h1>
      <h2 class="project-tagline">Presentation Project for DSC180 A03</h2>
      <h2 class="project-tagline">Authors: Brandon Vinhnee, Tej Patel, Abhishek Nisha Anish </h2>
      
        <a href="https://github.com/abhianish0105/DSC180B-Q2-Project" class="btn">View on GitHub</a>
      
      
    </header>

    <main id="content" class="main-content" role="main">
      <h2 id="what-we-did">Introduction</h2>

<p>
In this ever growing period of chaos where gun violence seems to be spiraling out of control, it is important to consider the opinions of people who live in cities and communities affected by this epidemic. There is most likely no solution that would make everyone happy, but through sentiment analysis, the general opinions can be deduced and even used to influence these impactful decisions. Twitter is a microblogging and social media platform that has amassed an enormous platform of around 206 million daily active users that account for approximately 500 million tweets per day. This popularity can be attributed to the fact that users feel enabled to talk freely about virtually anything they want, including their daily lives or topics that they are passionate about. With this kind of presence, it is only natural that the controversial topic of gun control became a huge subject matter due to recent tragic events. Through sentiment analysis and the chosen machine learning models, the collected Tweets will be classified as either positive, negative, or neutral and through a majority voting manner, the common view will be identified.

<br> <br>Previous research has worked towards this goal as well but several studies encountered shortcomings as a result of the methods that were utilized. In one such study done by Kaur [2], sentiment analysis was performed using a deep learning algorithm that designed a hybrid heterogeneous support vector machine. The limitation of this model was that it was not as effective for Tweets in different languages. Chakraborty [3] used the LSTM model on two types of rated Tweets, but some issues that were encountered included that it failed to find the most common words for polarity analysis and it was not able to reach the preferred validation accuracy with the given data. In this paper, the data goes through extraction, preprocessing, and classification so as to avoid these limitations. By taking the Twitter data from both the present and the time of the pandemic, this paper will also provide conclusions about the opinions from these two different periods to examine any differences. It is important that data is collected from both of these times as it is hypothesized that the sentiment towards gun control would be different during a time when events such as mass shootings were down compared to when there was a large spike in them.

<br> <br>The sample that will be used comes directly from the Twitter API. A Twitter firehose will be connected to a Pulsar Topic in DataStax Astra. The topic is then transformed with one Pulsar Function and the output is written to a second Pulsar Topic. Data will first be transformed using a Python script and then a machine learning model will be applied to measure sentiment and produce real-time analytics. This study will focus on gun control sentiment in the United States, so Twitter data will be filtered accordingly. Another important filter will be the time frame as we want to focus on Tweets from the time of the pandemic to now. Filtering in such a way makes the data suitable for the goal of this paper as this helps us target a certain area of Tweets while keeping a large enough dataset. Additionally, another part of the data that will be important in our analysis would be the labels that we choose to give our data. We could use this data along with TF-IDF and/or Word Embedding methods to figure out whether the particular data analyzed belongs to a positive, negative or neutral sentiment label.<figure>
  <img src="image_filepath" alt="figure_to_replace" />
</figure>
</p>

<h2 id="Methods">Methods</a></h2>
<p>
1. Make use of Astra Streaming in conjunction with Pulsar to stream Tweets. <br>
2. Research prominent events, such as the Monterey Park tragedy, and controversial points of
conversation regarding gun control for use as keywords. <br> 
3. Filter out Tweets based on keywords for designated topics. <br>
4. Store Tweets in separate databases for each topic of interest. <br>
5. Run chosen pre-trained machine learning model from HuggingFace to identify sentiment
regarding respective topics.
</p>

<figure>
  <img src="https://github.com/abhianish0105/DSC180B-Q2-Project/blob/gh-pages/images/method_diagram.png?raw=true" alt="Pipeline Architecture">
</figure>

<p>
To live-stream our Twitter data, there were a wide variety of techniques to access Tweets in real time from the Twitter API. After thorough research of these techniques, we decided to use Tweepy, a well-documented python library with streaming and filtering capabilities that seemed like it would be a perfect fit in the scope of our project. The second crucial portion for developing the architecture of the project was setting up a streaming platform for the Tweets to be sent to for preprocessing and further analysis. For this portion, we chose to use Astra Streaming in conjunction with Pulsar, a pay-as-you go streaming service, which had three capabilities we needed to continue – the ability to handle input code to receive raw Tweet data as a consumer, pass this data through to a function to handle data preprocessing, and finally consume the final Tweets and apply a machine learning model to receive the sentiment of the message.

<br> <br> To go further in depth, our streaming architecture started with Tweepy, with the main streaming capabilities coming from Tweepy’s StreamingClient Class. This class allowed for the raw tweets to be taken in from Twitter in real time. From here, we implemented the streaming class into our producer code, which produced the Tweets in real-time, and sent them to our Astra input topic. Instead of running our producer code directly from the producer file, we chose to implement a sort of “runner” file which created an instance of the producer class as well as the Tweepy streaming class, added preliminary filters which got certain keywords we wanted within our queries, as well as removing Tweets with unnecessary media, tags, etc. This file was responsible for sending the tweets to our input topic. The next part of our streaming architecture is the function, which reads the tweets from input topic, and within our specific function, applied a regex to remove all links from the tweets we wanted to pull. From the function, the tweets would be passed to our output topic, ultimately to be read by our consumer. Within our consumer code, we feed in our processed Tweets to our pre-trained Natural Language Processing (NLP) model adapted from HuggingFace, which outputs a score and label based on the sentiment of the Tweet being negative, positive, or neutral. This model, called twitter-roberta-base-sentiment-latest by Cardiff NLP, has been trained on over 124 million tweets, and has been adjusted for sentiment analysis with the TweetEval benchmark. We decided to choose this model for our analysis as this model was specifically trained to analyze sentiments from tweets, which was the backbone of our analysis. With these sentiments, we chose to measure our output by counting the number of each sentiment in real time as Tweets are fed into our pipeline, and updated these counts continuously in a CSV. Once all our data was acquired for every keyword(s) query, we created visualizations such as pie charts to show the proportion of each sentiment per query and two histograms showing how the sentiment scores were distributed for two of our queries. By doing this, we were able to compare the results to our initial hypothesis and also understand the polarity of these sentiments, whether or not they were “extremely” leaning one way or just slightly.

<br> <br> However, a Twitter developer announced that on February 9th, 2023, support for free access to the Twitter API would no longer be available, limiting our options for continuation of the project. With this constraint in mind, a new task was decided upon, in that with the short timeframe left for free API access, we would collect as much data that we could in the form of tweets, and store them in databases based on the keywords we used to filter the livestream. The same streaming method as described above was used, however without passing in the tweets through the model, as this was a time consuming task that could be done later without the use of the Twitter API. Instead, the tweet data was simply written to the file, and the model was run on the database after all data was collected.
</p>
    
<h2 id="Results">Results</a></h2>
<p>
TEXT TO REPLACE
</p>
  
<h2 id="Conclusion">Conclusion</a></h2>
<p>
TEXT TO REPLACE
</p>

<h4 id="Appendix">Appendix</a></h4>
<p>
TEXT TO REPLACE
</p>

<h4 id="Contributions">Contributions</a></h4>
<p>
TEXT TO REPLACE
</p>

      <footer class="site-footer">
        
          <span class="site-footer-owner"><a href="https://github.com/abhianish0105/DSC180B-Q2-Project">Website</a> is maintained by <a href="https://github.com/abhianish0105">Abhishek Nisha Anish, Brandon Vinhnee, Tej Patel</a>.</span>
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>
    </main>
  </body>
</html>
